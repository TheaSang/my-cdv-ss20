# Week4 Reading Response —— Thea(Sang)

**How to technical tools promise to "fair out" the remaining discrimination that exist in social/welfare systems? In how far can they succeed, in which ways do they fail?**

As the writer mentioned in the podcast, the poor have been stigmatized throughout history. The algometric seems to fair out the remaining discrimination that exists in previous social systems because all the decisions are made by the “objective” algometric system. Admittedly, flagrant discriminations are covered. However, the different subsystems related to each other and influenced each other and lead to discrimination within the whole social systems. For example, the poor may ask more help from the local states and will be collected more data and further be evaluated as high-risk people because of their previous records, which may further lead them to limited resources and harder situations. Once the feedback loop forms, the whole system enviably fails to be objective and fair.


**Imagine, what could this (following quotes) mean in the widest sense?
"The state doesn't need a cop to kill a person" and "electronic incarceration"**

Breaking up a family or denying people access to housing or food or medical care can easily kill people. These decisions can be made depending on the algorithm system. Just like the women who had cancer cannot access medical care because she missed the telephone interview and ended dying. It seems an algorithmic fault. However, it is hard to determine whether it is an accident or an intentional event because the whole system is extremely complex. It is a combination of political decisions, human beings, and technological systems. There exist too much bias, mistakes, and accidents. Thus, it might be easier for some people to make intentional decisions that may lead to the tragedy of other people but get rid out of the punishment and suspicious because the algorithm system can rationalize every decision.  


**What do you understand this to mean?
"systems act as a kind of 'empathy-overwrite"**

The state wants to use the algorithm system to distinguish the truly worthy people from those who are “lazy or dishonest”. When people want to get help from the state, they need to provide detailed information and go through a complex review mechanism. People are essentially incarcerated and continually evaluated by the agrammatic system. The system is more like a moral diagnosis rather than decides whether people deserve help or not. Decision-makers may be comforted because they think the most deserving people are getting help. However, each one has basic human rights to access housing, education, medical rights.


**China is much more advanced and expansive when it comes to applying technical solutions to societal processes or instant challenges (recent example). Try to point example cases in China that are in accordance or in opposition to the problematics discussed in the podcast. Perhaps you can think of
"technical systems not well thought-through about what their impace on human beings is"**

The cases in China show the same problematics discussed in the podcast. Mentioned in the New York Times, just like the risk system in American, the Health Code is also not detailly explained by governments. Using public transportation, shopping in the supermarkets or just passing by a certain road may lead to the transformation of the Health Code. Those who are ordered to isolate themselves are fearful and bewildering as they have no idea why. But I think the Health Code system applied in the serious outbreak is different from the risk evaluation system mentioned in the podcast. The blurry information of the Health Code may help to force people to stay at home during the extremely serious outbreak. Admittedly, detailed information and standards of evaluation may help people to avoid high-risk activities. But blurry information which leads to a certain degree of fear can also regulate the behaviors of users. Besides, some people may take advantage of loopholes to keep their Health Code green if they clearly know the detailed algorithm and standards of the Health Code system. After all, there is no shortage of such news that people take advantage of the loophole of regulations and spread the virus. However, with the recovery of normal life, the problems caused by the Health Code system should be paid more attention. If people lose their basic rights because of their Health Code becomes red and they don’t know why it must lead to dissatisfaction and fear. Perhaps the person who cannot afford a car and has to use public transportation will have a higher risk than those who can drive the private cars to work. These might lead to more profound discrimination and unfairness. Besides, after the outbreak, how to deal with the Health Code system is also a problem because it contains a huge amount of private information. I will worry about whether it will be used as a control and supervise system in the future.
